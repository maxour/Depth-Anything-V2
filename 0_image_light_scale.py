# åˆ‡æ¢åˆ°ç‹¬ç«‹ç¯å¢ƒ
# python3 -m venv venv
# source venv/bin/activate
# B. å‰ç«¯å¦‚ä½•ä½¿ç”¨ Scale Gridï¼Ÿ
# è¿™ä»½ä»£ç ç”Ÿæˆçš„ JSON åŒ…å«äº†ä¸€ä¸ªç»“æ„åŒ–çš„ç½‘æ ¼æ•°æ®ã€‚åœ¨å‰ç«¯ï¼ˆThree.js / React / Vueï¼‰ä¸­å®ç°å°å­©è·‘åŠ¨é€»è¾‘éå¸¸ç®€å•ï¼š
# åŠ è½½ JSONï¼šå°† nav_mesh.points å­˜å…¥ä¸€ä¸ªäºŒç»´æ•°ç»„ Grid[row][col]ã€‚
# è·å– Avatar å½“å‰åæ ‡ï¼šå‡è®¾å°å­©è·‘åˆ°äº† u = 0.55, v = 0.82ã€‚
# æŸ¥æ‰¾æœ€è¿‘ç½‘æ ¼ç‚¹ï¼šu=0.55 ä»‹äºç½‘æ ¼åˆ— 19 å’Œ 20 ä¹‹é—´ã€‚v=0.82 ä»‹äºç½‘æ ¼è¡Œ 6 å’Œ 7 ä¹‹é—´ã€‚
# è®¡ç®— Scaleï¼šæ‰¾åˆ°è¿™ 4 ä¸ªç›¸é‚»ç‚¹çš„ scale å€¼ã€‚
# ä½¿ç”¨ç®€å•çš„åŒçº¿æ€§æ’å€¼ (Bilinear Interpolation) ç®—å‡ºå½“å‰ç‚¹çš„ç²¾ç¡® Scaleã€‚
# å…¬å¼ï¼š$Scale = w_1 S_{TL} + w_2 S_{TR} + w_3 S_{BL} + w_4 S_{BR}$
import cv2
import numpy as np
import json
import argparse
import os

def analyze_scene_advanced(rgb_path, depth_path, output_dir):
    # 1. è¯»å–å›¾åƒ
    rgb_img = cv2.imread(rgb_path)
    depth_img = cv2.imread(depth_path, cv2.IMREAD_GRAYSCALE) # å•é€šé“æ·±åº¦
    
    if rgb_img is None or depth_img is None:
        print("âŒ Error: æ— æ³•è¯»å– RGB æˆ– Depth å›¾ç‰‡")
        return

    h, w = rgb_img.shape[:2]
    print(f"ğŸ–¼  Processing: {w}x{h}")

    # ==========================================
    # Part 1: é«˜çº§å¤šå…‰æºæ£€æµ‹ (Multi-Light Detection)
    # ==========================================
    
    # è½¬æ¢ä¸ºç°åº¦
    gray = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)
    
    # ç­–ç•¥ï¼šä¸è¿›è¡Œå¤§èŒƒå›´æ¨¡ç³Šï¼Œä¿ç•™é”åˆ©çš„é«˜å…‰ç‚¹
    # ä»…åšæå¾®å°çš„æ¨¡ç³Šä»¥æ¶ˆé™¤å™ªç‚¹
    gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)
    
    # é˜ˆå€¼åŒ–ï¼šåªæå–æäº®åŒºåŸŸ (äº®åº¦ > 240/255)
    # è¿™èƒ½æœ‰æ•ˆè¿‡æ»¤æ‰æ™®é€šçš„ç™½äº‘ï¼Œåªç•™ä¸‹å¤ªé˜³æˆ–è·¯ç¯æ ¸å¿ƒ
    ret, thresh = cv2.threshold(gray_blur, 240, 255, cv2.THRESH_BINARY)
    
    # è¿é€šåŸŸåˆ†æï¼šæ‰¾å‡ºæ‰€æœ‰ç‹¬ç«‹çš„å‘å…‰å—
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)
    
    light_sources = []
    
    # éå†æ‰€æœ‰è¿é€šåŸŸ (label 0 æ˜¯èƒŒæ™¯ï¼Œè·³è¿‡)
    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        
        # è¿‡æ»¤æ‰å¤ªå°çš„å™ªç‚¹ (ä¾‹å¦‚åªæœ‰ 1-2 ä¸ªåƒç´ çš„äº®ç‚¹)
        if area < 5: 
            continue
            
        # è·å–è¯¥åŒºåŸŸçš„ä¸­å¿ƒåæ ‡
        cx, cy = centroids[i]
        
        # è·å–è¯¥åŒºåŸŸå†…çš„æœ€å¤§äº®åº¦ (åœ¨åŸå§‹ç°åº¦å›¾ä¸Šæ‰¾ï¼Œè€Œä¸æ˜¯äºŒå€¼å›¾)
        # åˆ›å»ºä¸€ä¸ªæ©ç åªæå–å½“å‰å…‰æºåŒºåŸŸ
        mask = (labels == i).astype(np.uint8)
        min_val, max_val, _, max_loc = cv2.minMaxLoc(gray, mask=mask)
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼šé€šå¸¸å¤ªé˜³æ˜¯ æœ€äº® ä¸” ç›¸å¯¹é›†ä¸­
        # è¿™é‡Œæˆ‘ä»¬ä¸»è¦æŒ‰ max_intensity æ’åºï¼Œå¦‚æœäº®åº¦ä¸€æ ·ï¼ŒæŒ‰é¢ç§¯æ’åº
        score = max_val * 1000 + area 
        
        light_sources.append({
            "id": i,
            "type": "point_light",
            "score": float(score),
            "intensity": int(max_val), # 0-255
            "area": int(area),
            "pixel_coords": [int(cx), int(cy)],
            "uv": [round(cx/w, 4), round(cy/h, 4)],
            # å°† UV æ˜ å°„åˆ° 360 åº¦ (U=0.5 -> 180åº¦)
            "angle_yaw": round((cx/w) * 360, 2),
            "angle_pitch": round((cy/h) * 180 - 90, 2) # -90(åº•) åˆ° 90(é¡¶)
        })
    
    # æŒ‰è¯„åˆ†é™åºæ’åˆ— (æœ€å¯èƒ½æ˜¯å¤ªé˜³çš„æ’ç¬¬ä¸€)
    light_sources.sort(key=lambda x: x["score"], reverse=True)
    
    # å–å‰ 5 ä¸ªå…‰æº (é€‚åº”å¤œæ™¯å¤šè·¯ç¯æƒ…å†µ)
    top_lights = light_sources[:5]

    # ==========================================
    # Part 2: ç½‘æ ¼åŒ–ç¼©æ”¾åœ°å›¾ (Grid Scale Map)
    # ==========================================
    
    # é…ç½®ç½‘æ ¼å¯†åº¦
    # ä»…è¦†ç›–ä¸‹åŠéƒ¨åˆ† (Ground)
    GRID_ROWS = 10  # å‚ç›´æ–¹å‘è¡Œæ•° (åªå–ä¸‹åŠæˆª)
    GRID_COLS = 36  # æ°´å¹³æ–¹å‘åˆ—æ•° (æ¯10åº¦ä¸€ä¸ªç‚¹)
    
    scale_points = []
    
    # å‚ç›´æ–¹å‘ï¼šä» 50% (åœ°å¹³çº¿) åˆ° 95% (è„šä¸‹)
    # é¿å… 100% æç‚¹ï¼Œå› ä¸ºé‚£é‡Œè´´å›¾æ‰­æ›²æå¤§
    row_steps = np.linspace(0.55, 0.95, GRID_ROWS)
    col_steps = np.linspace(0.0, 1.0, GRID_COLS, endpoint=False) # 0-360åº¦
    
    for r_idx, v_ratio in enumerate(row_steps):
        for c_idx, u_ratio in enumerate(col_steps):
            
            px = int(u_ratio * w)
            py = int(v_ratio * h)
            
            # è¾¹ç•Œä¿æŠ¤
            px = np.clip(px, 0, w-1)
            py = np.clip(py, 0, h-1)
            
            # --- æ·±åº¦é‡‡æ ·ä¼˜åŒ– ---
            # ä¸è¦åªå–å•ç‚¹åƒç´ ï¼Œå– 5x5 åŒºåŸŸå¹³å‡å€¼ï¼Œé˜²æ­¢è¸©åˆ°å™ªç‚¹
            patch_size = 5
            y1 = max(0, py - patch_size // 2)
            y2 = min(h, py + patch_size // 2 + 1)
            x1 = max(0, px - patch_size // 2)
            x2 = min(w, px + patch_size // 2 + 1)
            
            depth_patch = depth_img[y1:y2, x1:x2]
            if depth_patch.size == 0: continue
            avg_depth = np.mean(depth_patch)
            
            # --- ç¼©æ”¾ç®—æ³• ---
            # 1. æ·±åº¦åŸºç¡€ç¼©æ”¾ (Depth Scale): è¶Šç™½(255)è¶Šè¿‘ï¼Œè¶Šå¤§
            #    å…¬å¼ï¼š(depth / 255) ^ gamma
            # å‡è®¾: Depth 255 (æœ€è¿‘) -> Scale 2.5
            #       Depth 50  (è¿œ)   -> Scale 0.3
            # ä½ å¯ä»¥è°ƒèŠ‚ gamma æŒ‡æ•°æ¥æ§åˆ¶è¡°å‡é€Ÿåº¦
            base_scale = (avg_depth / 255.0) ** 1.0
            
            # 2. æŠ•å½±ä¿®æ­£ (Projection Correction):
            #    åœ¨ç­‰è·æŸ±çŠ¶æŠ•å½±ä¸­ï¼Œè¶Šé è¿‘åº•éƒ¨ï¼Œåƒç´ è¢«æ¨ªå‘æ‹‰ä¼¸å¾—è¶Šå‰å®³ã€‚
            #    ä¸ºäº†è§†è§‰è¡¥å¿ï¼Œé€šå¸¸è¶Šé è¿‘åº•éƒ¨ç‰©ä½“åº”è¯¥ç¨å¾®â€œæ‰/å®½â€ä¸€ç‚¹ï¼Œæˆ–è€…æ•´ä½“è°ƒå¤§ã€‚
            #    è¿™é‡Œåšä¸€ä¸ªç®€å•çš„çº¿æ€§è¡¥å¿ï¼šè¶Šé ä¸‹(væ¥è¿‘1)ï¼ŒScale é€‚å½“æ”¾å¤§
            projection_factor = 1.0 + (v_ratio - 0.5) * 0.8
            
            final_scale = base_scale * projection_factor * 2.5 # ä¹˜ä¸€ä¸ªç³»æ•°è®©æ•´ä½“æ•°å€¼å¥½çœ‹
            final_scale = np.clip(final_scale, 0.1, 5.0) # é™åˆ¶èŒƒå›´
            
            scale_points.append({
                "grid_pos": [c_idx, r_idx], # ç½‘æ ¼ç´¢å¼•ï¼Œæ–¹ä¾¿å‰ç«¯æŸ¥æ‰¾
                "uv": [round(u_ratio, 4), round(v_ratio, 4)],
                "pixel": [px, py],
                "depth_val": int(avg_depth),
                "scale": round(float(final_scale), 3)
            })

    # ==========================
    # Part 3: è¾“å‡ºä¸å¯è§†åŒ–
    # ==========================
    
    # ç»˜åˆ¶ Debug å›¾ç‰‡
    debug_img = rgb_img.copy()
    
    # 1. ç”»å…‰æº
    for i, light in enumerate(top_lights):
        cx, cy = light["pixel_coords"]
        # ç¬¬ä¸€å(å¤ªé˜³)ç”¨ç²—ç»¿è‰²åœˆï¼Œå…¶ä»–ç”¨ç»†é»„è‰²åœˆ
        color = (0, 255, 0) if i == 0 else (0, 255, 255) 
        thickness = 5 if i == 0 else 2
        radius = int(np.sqrt(light["area"])) + 20
        
        cv2.circle(debug_img, (cx, cy), radius, color, thickness)
        cv2.putText(debug_img, f"Light {i+1}", (cx+radius, cy), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # 2. ç»˜åˆ¶ç¼©æ”¾ç½‘æ ¼ç‚¹ (é‡ç‚¹ä¿®æ”¹éƒ¨åˆ†)
    print("ğŸ¨ Drawing Scale Circles...")
    
    for pt in scale_points:
        px, py = pt["pixel"]
        scale = pt["scale"]
        
        # --- æ ¸å¿ƒä¿®æ­£é€»è¾‘ ---
        # æˆ‘ä»¬ä¸èƒ½ç”¨å›ºå®šçš„åƒç´ å€¼ï¼Œå¿…é¡»åŸºäºå›¾ç‰‡é«˜åº¦ (h) è®¡ç®—ã€‚
        # è®¾å®šï¼šåœ¨ Scale=1.0 æ—¶ï¼Œåœ†åœˆåŠå¾„æ˜¯å›¾ç‰‡é«˜åº¦çš„ 2% (å¤§çº¦æ˜¯ä¸€ä¸ªäººçš„å åœ°åŠå¾„)
        # ä¾‹å¦‚ 2880p é«˜åº¦ -> 1.0 scale = 57 åƒç´ åŠå¾„
        base_radius_ratio = 0.02 
        radius_px = int(h * base_radius_ratio * scale)
        
        # ç¡®ä¿æœ€å°å¯è§æ€§ (è‡³å°‘3ä¸ªåƒç´ )
        radius_px = max(radius_px, 3)
        
        # A. ç»˜åˆ¶çº¢ç‚¹ (è„šåº•é”šç‚¹) - å®å¿ƒ
        # é”šç‚¹å¤§å°ä¹Ÿéšåˆ†è¾¨ç‡å˜åŒ–ï¼Œè®¾ä¸ºé«˜åº¦çš„ 0.3%
        anchor_radius = max(int(h * 0.003), 2)
        cv2.circle(debug_img, (px, py), anchor_radius, (0, 0, 255), -1) 
        
        # B. ç»˜åˆ¶è“åœˆ (Avatar ç¼©æ”¾å‚è€ƒ) - ç©ºå¿ƒ
        # çº¿å®½éšåˆ†è¾¨ç‡å˜åŒ–
        line_thickness = max(int(h * 0.001), 1)
        cv2.circle(debug_img, (px, py), radius_px, (255, 200, 0), line_thickness) 

        # (å¯é€‰) æ¯éš”å‡ ä¸ªç‚¹æ ‡ä¸€ä¸‹æ•°å€¼ï¼Œé˜²æ­¢å¤ªå¯†é›†
        if pt["grid_pos"][0] % 4 == 0 and pt["grid_pos"][1] % 2 == 0:
            font_scale = h / 2000.0 # å­—ä½“éšå›¾ç‰‡å¤§å°ç¼©æ”¾
            cv2.putText(debug_img, f"{scale:.2f}", (px + 10, py), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), 2)

    # ä¿å­˜
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    json_path = os.path.join(output_dir, "scene_meta_v2.json")
    vis_path = os.path.join(output_dir, "scene_debug_v2.jpg")
    
    output_data = {
        "scene_name": os.path.basename(rgb_path),
        "resolution": [w, h],
        "lights": top_lights,
        "nav_mesh": {
            "type": "grid",
            "rows": GRID_ROWS,
            "cols": GRID_COLS,
            "points": scale_points
        }
    }
    
    with open(json_path, 'w') as f:
        json.dump(output_data, f, indent=4)
        
    cv2.imwrite(vis_path, debug_img)
    
    print(f"âœ… Analysis Complete.")
    print(f"   - Found {len(top_lights)} lights.")
    print(f"   - Generated {len(scale_points)} scale points.")
    print(f"   - JSON: {json_path}")
    print(f"   - Debug Img: {vis_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--rgb', required=True)
    parser.add_argument('--depth', required=True)
    parser.add_argument('--out', default='./out')
    args = parser.parse_args()
    
    analyze_scene_advanced(args.rgb, args.depth, args.out)