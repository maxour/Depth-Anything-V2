# åˆ‡æ¢åˆ°ç‹¬ç«‹ç¯å¢ƒ
# python3 -m venv venv
# source venv/bin/activate
# pip3 install -r requirements.txt
import cv2
import torch
import numpy as np
import os
import argparse
from depth_anything_v2.dpt import DepthAnythingV2

# === é…ç½® ===
DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'
# è¿™é‡Œçš„ encoder å¿…é¡»å’Œä½ ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶åä¸€è‡´ (vits, vitb, vitl)
MODEL_CONFIG = {
    'encoder': 'vits', 
    'features': 64, 
    'out_channels': [48, 96, 192, 384]
}
MODEL_PATH = 'checkpoints/depth_anything_v2_vits.pth' # ç¡®ä¿è·¯å¾„æ­£ç¡®

def extract_and_process(video_path, frame_index, output_dir):
    # 1. åˆå§‹åŒ–æ¨¡å‹
    print(f"ğŸš€ Loading model to {DEVICE}...")
    depth_model = DepthAnythingV2(**MODEL_CONFIG)
    depth_model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
    depth_model = depth_model.to(DEVICE).eval()

    # 2. è¯»å–è§†é¢‘æŒ‡å®šå¸§
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if frame_index >= total_frames:
        print(f"âŒ Error: Frame {frame_index} out of bounds (Total: {total_frames})")
        return

    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
    ret, frame = cap.read()
    cap.release()

    if not ret:
        print("âŒ Error: Could not read frame.")
        return

    h, w = frame.shape[:2]
    print(f"ğŸ“¸ Captured Frame {frame_index} | Resolution: {w}x{h}")

    # 3. å¤„ç†æ¥ç¼ (The Padding Trick)
    # å·¦å³å„æ‰©å…… 10% çš„å†…å®¹ï¼Œè®©æ¨¡å‹çŸ¥é“è¾¹ç•Œæ˜¯è¿ç»­çš„
    pad_w = int(w * 0.1) 
    # numpyåˆ‡ç‰‡: [æ‰€æœ‰è¡Œ, å·¦ä¾§pad_wåˆ—]
    left_part = frame[:, 0:pad_w] 
    # numpyåˆ‡ç‰‡: [æ‰€æœ‰è¡Œ, å³ä¾§æœ€åpad_wåˆ—]
    right_part = frame[:, w-pad_w:w] 

    # æ‹¼æ¥: [å³è¾¹æœ«å°¾] + [åŸå§‹å›¾ç‰‡] + [å·¦è¾¹å¼€å¤´]
    padded_frame = np.concatenate((right_part, frame, left_part), axis=1)

    # 4. æ·±åº¦æ¨ç†
    # input_size=1024 æˆ– 2048 èƒ½è·å¾—æ›´ç²¾ç»†çš„çº¹ç†ï¼Œä½†é€Ÿåº¦å˜æ…¢
    # Mac M4 å»ºè®®å°è¯• 1024 æˆ– 1536
    depth = depth_model.infer_image(padded_frame, input_size=1024)

    # 5. åå¤„ç†ä¸è£åˆ‡
    # å½’ä¸€åŒ–åˆ° 0-255
    depth_normalized = (depth - depth.min()) / (depth.max() - depth.min()) * 255.0
    depth_uint8 = depth_normalized.astype(np.uint8)

    # æŠŠä¹‹å‰æ‰©å……çš„ 10% åˆ‡æ‰ï¼Œåªä¿ç•™ä¸­é—´åŸæœ¬çš„éƒ¨åˆ†
    # æ³¨æ„ï¼šinfer_image è¾“å‡ºçš„å°ºå¯¸é€šå¸¸å’Œè¾“å…¥ä¸€è‡´ï¼Œä½†ä¸ºäº†ä¿é™©ï¼Œæˆ‘ä»¬æŒ‰æ¯”ä¾‹è£åˆ‡
    out_h, out_w = depth_uint8.shape
    real_w = out_w - (pad_w * 2)
    # è¿™é‡Œçš„è£åˆ‡è¦éå¸¸å°å¿ƒï¼Œç¡®ä¿åƒç´ å¯¹é½
    # ç”±äº infer_image å¯èƒ½ä¼šæœ‰ resize è¡Œä¸ºï¼Œæœ€å¥½æ˜¯ resize å› padded å°ºå¯¸å† crop
    # ä½† DepthAnythingV2 çš„ infer_image è¿”å›çš„æ˜¯åŸå›¾å¤§å°çš„ numpy æ•°ç»„ï¼Œæ‰€ä»¥ç›´æ¥ crop å³å¯
    
    final_depth = depth_uint8[:, pad_w : out_w - pad_w]
    
    # ç¡®ä¿å°ºå¯¸ä¸¥æ ¼åŒ¹é…åŸå›¾ (åº”å¯¹å¯èƒ½çš„èˆå…¥è¯¯å·®)
    final_depth = cv2.resize(final_depth, (w, h))

    # 6. ä¿å­˜ç»“æœ
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    name = os.path.splitext(os.path.basename(video_path))[0]
    
    # ä¿å­˜åŸå›¾ (ä½œä¸ºçº¹ç†)
    cv2.imwrite(os.path.join(output_dir, f"{name}_f{frame_index}_RGB.jpg"), frame)
    
    # ä¿å­˜æ·±åº¦å›¾ (ä½œä¸º Displacement/Depth)
    cv2.imwrite(os.path.join(output_dir, f"{name}_f{frame_index}_Depth.png"), final_depth)
    
    # ä¿å­˜åˆæˆé¢„è§ˆ (ä¸Šä¸‹æ’åˆ—)
    depth_color = cv2.cvtColor(final_depth, cv2.COLOR_GRAY2BGR)
    preview = np.vstack((frame, depth_color))
    cv2.imwrite(os.path.join(output_dir, f"{name}_f{frame_index}_Preview.jpg"), preview)

    print(f"âœ… Done! Files saved in {output_dir}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--video', type=str, required=True, help='Path to insv/mp4 video')
    parser.add_argument('--frame', type=int, default=0, help='Frame index to extract')
    parser.add_argument('--out', type=str, default='./out', help='Output folder')
    
    args = parser.parse_args()
    extract_and_process(args.video, args.frame, args.out)